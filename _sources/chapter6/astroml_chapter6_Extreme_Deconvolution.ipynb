{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fdb5484",
   "metadata": {
    "colab_type": "text",
    "id": "_aG935uWHf7s"
   },
   "source": [
    "# Extreme Deconvolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ff6a19",
   "metadata": {
    "colab_type": "text",
    "id": "anSHOmvFHf7y"
   },
   "source": [
    "## Introduction\n",
    "**Extreme deconvolution (XD)** combines Baysian extimation and Gaussian model in the algorithm to correct data with measurement errors.  \n",
    "The algorithm basically assumes an observed value ${x_i}$, true value ${v_i}$, and noise ${\\epsilon}$ \n",
    "have the following relationship:\n",
    "\n",
    "$${x_i} = {R_i}{v_i}+{\\epsilon_i}$$  \n",
    "\n",
    "where ${R_i}$ is a projection matrix. After we compute this matrix using assumed Gaussian model, we are able to convert\n",
    "noisy data back to true data.  \n",
    "  \n",
    "In section A, we plot four scattered point distribution graphs to show\n",
    "how XD corrects noisy unsupervised data.  \n",
    "(\"Unsupervised\" here means no additional information is given on the data).  \n",
    "\n",
    "In section B, we will apply real stellar data sample and see how XD works in correcting data distribution. Again we will plot four graphs in comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569f422c",
   "metadata": {
    "colab_type": "text",
    "id": "62DBqXT-Hf7z"
   },
   "source": [
    "## Import Data and Functions\n",
    "The functions we need are in astroML. XDGMM is the main function we call to perform extreme deconvolution.  \n",
    "The data we use to in this demostration is from the Stripe 82 Standard Star Catalog (high SNR) and single epoch observations (low SNR).  \n",
    "More information about data used is in references."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac632dc",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EJWmPRa_Hf71"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from astroML.density_estimation import XDGMM\n",
    "from astroML.plotting.tools import draw_ellipse\n",
    "\n",
    "from astroML.crossmatch import crossmatch\n",
    "from astroML.datasets import fetch_sdss_S82standards, fetch_imaging_sample\n",
    "from astroML.stats import sigmaG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d45e8f5",
   "metadata": {
    "colab_type": "text",
    "id": "UACW9fCj9DCC"
   },
   "source": [
    "## A. XD on a generated dataset\n",
    "In the first section, we will explore how XD works using randomly generated data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c188fd8",
   "metadata": {
    "colab_type": "text",
    "id": "bCVMxbP3Hf8B"
   },
   "source": [
    "### 1. Generate true data\n",
    "We first generate a distribution of \"true data\" using radomized numbers.\n",
    "We will plot this data set as a reference to compare with the model derived from estimation with XD.  \n",
    "Users can change sample size (N) to experiment the effectiveness of this method: Bigger sample size gives more information about the data set and is easier to converge, however it takes longer time to run in the method. The method may fail to converge due to small sample size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a31497",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7866,
     "status": "ok",
     "timestamp": 1591975457864,
     "user": {
      "displayName": "Brigitta Sipocz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgSZ5lvx2m0gmkej0jid6to7H2aVpPwrDwknsPBVg=s64",
      "userId": "02384660603430700458"
     },
     "user_tz": 420
    },
    "id": "xHZZd3pBHf8C",
    "outputId": "31a255e6-0ac6-4b36-87d8-72ccdfa94282"
   },
   "outputs": [],
   "source": [
    "# Sample the dataset. \n",
    "# Here we use sample size = 400 in the example, \n",
    "# which converges in shorter time, and gives reasonable result.\n",
    "N = 400\n",
    "np.random.seed(0)\n",
    "\n",
    "# generate the true data\n",
    "x_true = (1.4 + 2 * np.random.random(N)) ** 2\n",
    "y_true = 0.1 * x_true ** 2\n",
    "\n",
    "# add scatter to \"true\" distribution\n",
    "dx = 0.1 + 4. / x_true ** 2\n",
    "dy = 0.1 + 10. / x_true ** 2\n",
    "\n",
    "x_true += np.random.normal(0, dx, N)\n",
    "y_true += np.random.normal(0, dy, N)\n",
    "\n",
    "# define a function to plot all distributions in the same format\n",
    "def plot_distribution(text, sample_x, sample_y):\n",
    "    plt.figure(figsize=(5, 3.75))\n",
    "    plt.scatter(sample_x, sample_y, s=4,lw=0,c='k')\n",
    "    plt.xlim(-1, 13)\n",
    "    plt.ylim(-6, 16)\n",
    "    plt.xlabel('$x$')\n",
    "    plt.ylabel('$y$')\n",
    "    plt.title(text,fontsize=10)\n",
    "\n",
    "# plot true distribution\n",
    "plot_distribution('True Distribution', x_true, y_true)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec81c045",
   "metadata": {
    "colab_type": "text",
    "id": "SVVRSPtiHf8L"
   },
   "source": [
    "### 2. Generate noisy data\n",
    "We add some radom noisy onto the true data to model what we may observe from true distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fcb37b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8337,
     "status": "ok",
     "timestamp": 1591975458346,
     "user": {
      "displayName": "Brigitta Sipocz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgSZ5lvx2m0gmkej0jid6to7H2aVpPwrDwknsPBVg=s64",
      "userId": "02384660603430700458"
     },
     "user_tz": 420
    },
    "id": "GH7whTPTHf8M",
    "outputId": "04fbefc4-8ae8-4ea9-9331-f526c619693b"
   },
   "outputs": [],
   "source": [
    "# add noise to get the \"observed\" distribution\n",
    "dx = 0.2 + 0.5 * np.random.random(N)\n",
    "dy = 0.2 + 0.5 * np.random.random(N)\n",
    "\n",
    "x = x_true + np.random.normal(0, dx)\n",
    "y = y_true + np.random.normal(0, dy)\n",
    "\n",
    "# plot noisy distribution\n",
    "plot_distribution('Noisy Distribution', x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb078e9",
   "metadata": {
    "colab_type": "text",
    "id": "Q-52pq83Hf8U"
   },
   "source": [
    "### 3. Compute extreme deconvolution (XD)\n",
    "The code below computes the result.\n",
    "In the XDGMM method, *n_components* (integer) defines the number of Gaussian components to fit to the data.  \n",
    "*max_iter* (integer) defines number of EM iterations to perform (default as 100). Larger iteration number generally contributes better approximation to the true data, but takes longer time to execute.   \n",
    "This cell is expected to execute in a bit long time around 1 minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892a1724",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0wn-7euHHf8U"
   },
   "outputs": [],
   "source": [
    "# stack the results for computation\n",
    "X = np.vstack([x, y]).T\n",
    "Xerr = np.zeros(X.shape + X.shape[-1:])\n",
    "diag = np.arange(X.shape[-1])\n",
    "Xerr[:, diag, diag] = np.vstack([dx ** 2, dy ** 2]).T\n",
    "\n",
    "clf = XDGMM(n_components=10, max_iter=200)\n",
    "\n",
    "clf.fit(X, Xerr)\n",
    "sample = clf.sample(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9ddcf4",
   "metadata": {
    "colab_type": "text",
    "id": "_4PfSTinHf8b"
   },
   "source": [
    "### 4. Plot the result from XD\n",
    "We use scattered point to show the result of noisy data from XD correction. The plot shows a less scattered distribution \n",
    "than noisy data and even than true data, which better portraits a \"underlying distribution.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10b89a9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 495,
     "status": "ok",
     "timestamp": 1591975758079,
     "user": {
      "displayName": "Brigitta Sipocz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgSZ5lvx2m0gmkej0jid6to7H2aVpPwrDwknsPBVg=s64",
      "userId": "02384660603430700458"
     },
     "user_tz": 420
    },
    "id": "eWSW_Q-sHf8c",
    "outputId": "661d783a-9939-4d41-da07-88a5069ab275"
   },
   "outputs": [],
   "source": [
    "# plot noisy distribution\n",
    "plot_distribution('Extreme Deconvolution Resampling', sample[:, 0], sample[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1059d8c1",
   "metadata": {
    "colab_type": "text",
    "id": "1pebnvgMHf8j"
   },
   "source": [
    "### 5. Use subplots to show clear comparison\n",
    "We plot true distribution (top left), noisy distribution (top right), and resampled distribution from XD (bottom left)\n",
    "together to show a clear comparison for the effectiveness of this method in modeling.  \n",
    "In addition, we add a clustered representation of the distribution (bottom right) to show the use in locating clusters with\n",
    "XD method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d605880e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 291
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 725,
     "status": "ok",
     "timestamp": 1591975792941,
     "user": {
      "displayName": "Brigitta Sipocz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgSZ5lvx2m0gmkej0jid6to7H2aVpPwrDwknsPBVg=s64",
      "userId": "02384660603430700458"
     },
     "user_tz": 420
    },
    "id": "_sGiuoY1Hf8k",
    "outputId": "510122f9-1ff3-4dc5-c548-5cb6e6781a3e"
   },
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "fig = plt.figure(figsize=(5, 3.75))\n",
    "fig.subplots_adjust(left=0.1, right=0.95,\n",
    "                    bottom=0.1, top=0.95,\n",
    "                    wspace=0.02, hspace=0.02)\n",
    "\n",
    "ax1 = fig.add_subplot(221)\n",
    "ax1.scatter(x_true, y_true, s=4, lw=0, c='k')\n",
    "\n",
    "ax2 = fig.add_subplot(222)\n",
    "ax2.scatter(x, y, s=4, lw=0, c='k')\n",
    "\n",
    "ax3 = fig.add_subplot(223)\n",
    "ax3.scatter(sample[:, 0], sample[:, 1], s=4, lw=0, c='k')\n",
    "\n",
    "ax4 = fig.add_subplot(224)\n",
    "for i in range(clf.n_components):\n",
    "    draw_ellipse(clf.mu[i], clf.V[i], scales=[2], ax=ax4,\n",
    "                 ec='k', fc='gray', alpha=0.2)\n",
    "\n",
    "titles = [\"True Distribution\", \"Noisy Distribution\",\n",
    "          \"Extreme Deconvolution\\n  resampling\",\n",
    "          \"Extreme Deconvolution\\n  cluster locations\"]\n",
    "\n",
    "ax = [ax1, ax2, ax3, ax4]\n",
    "\n",
    "for i in range(4):\n",
    "    ax[i].set_xlim(-1, 13)\n",
    "    ax[i].set_ylim(-6, 16)\n",
    "\n",
    "    ax[i].xaxis.set_major_locator(plt.MultipleLocator(4))\n",
    "    ax[i].yaxis.set_major_locator(plt.MultipleLocator(5))\n",
    "\n",
    "    ax[i].text(0.05, 0.95, titles[i],\n",
    "               ha='left', va='top', transform=ax[i].transAxes)\n",
    "\n",
    "    if i in (0, 1):\n",
    "        ax[i].xaxis.set_major_formatter(plt.NullFormatter())\n",
    "    else:\n",
    "        ax[i].set_xlabel('$x$')\n",
    "\n",
    "    if i in (1, 3):\n",
    "        ax[i].yaxis.set_major_formatter(plt.NullFormatter())\n",
    "    else:\n",
    "        ax[i].set_ylabel('$y$')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fb8aee",
   "metadata": {
    "colab_type": "text",
    "id": "4zZ3ywWm_F0C"
   },
   "source": [
    "## B. XD on real star sample\n",
    "In this section, we use a set of standard stars from S82 (high SNR), and a set of noisy single epoch of stars (low SNR). We will perform XD on the noisy data and see how it resamples the data into clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1b590e",
   "metadata": {
    "colab_type": "text",
    "id": "BeTFD0Mt_SDg"
   },
   "source": [
    "### 1. Perform extinction correction on noisy sample\n",
    "First, we fix the star's true color from dust extinction in noisy data sample. We apply extinction correction curve defined as \n",
    "$C_{\\lambda} \\equiv \\frac{A_{\\lambda}}{A}$, where the value of $C_{\\lambda}$ for each band of S82 is from [Berry et al 2012](https://ui.adsabs.harvard.edu/abs/2012ApJ...757..166B/abstract)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52bd5eb",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C5g8OI3kHf8p"
   },
   "outputs": [],
   "source": [
    "# define u-g-r-i-z extinction from Berry et al, arXiv 1111.4985 multiply extinction by A_r\n",
    "extinction_vector = np.array([1.810, 1.400, 1.0, 0.759, 0.561])\n",
    "\n",
    "# Fetch and process the noisy imaging data\n",
    "data_noisy = fetch_imaging_sample()\n",
    "\n",
    "# select only stars\n",
    "data_noisy = data_noisy[data_noisy['type'] == 6]\n",
    "\n",
    "# Get the extinction-corrected magnitudes for each band\n",
    "X = np.vstack([data_noisy[f + 'RawPSF'] for f in 'ugriz']).T\n",
    "Xerr = np.vstack([data_noisy[f + 'psfErr'] for f in 'ugriz']).T\n",
    "\n",
    "# extinction terms from Berry et al, arXiv 1111.4985\n",
    "X -= (extinction_vector * data_noisy['rExtSFD'][:, None])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4434a5c4",
   "metadata": {
    "colab_type": "text",
    "id": "TLtG_p96_dN6"
   },
   "source": [
    "### 2. Perform extinction correction on standard sample\n",
    "Next, we stack the S82 star set and perform the same extinction correction on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e3f078",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N25D9j0eHf8u"
   },
   "outputs": [],
   "source": [
    "# Fetch and process the stacked imaging data\n",
    "data_stacked = fetch_sdss_S82standards()\n",
    "\n",
    "# cut to RA, DEC range of imaging sample\n",
    "RA = data_stacked['RA']\n",
    "DEC = data_stacked['DEC']\n",
    "data_stacked = data_stacked[(RA > 0) & (RA < 10) &\n",
    "                            (DEC > -1) & (DEC < 1)]\n",
    "\n",
    "# get stacked magnitudes for each band\n",
    "Y = np.vstack([data_stacked['mmu_' + f] for f in 'ugriz']).T\n",
    "Yerr = np.vstack([data_stacked['msig_' + f] for f in 'ugriz']).T\n",
    "\n",
    "# extinction terms from Berry et al, arXiv 1111.4985\n",
    "Y -= (extinction_vector * data_stacked['A_r'][:, None])\n",
    "\n",
    "# quality cuts\n",
    "g = Y[:, 1]\n",
    "mask = ((Yerr.max(1) < 0.05) &\n",
    "        (g < 20))\n",
    "data_stacked = data_stacked[mask]\n",
    "Y = Y[mask]\n",
    "Yerr = Yerr[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6fbba9",
   "metadata": {
    "colab_type": "text",
    "id": "MxmOsWnc_nKQ"
   },
   "source": [
    "### 3. Cross-match two data sets\n",
    "We use cross-match to match the noisy sample to standard sample, and make two sets comparable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe3e858",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 65148,
     "status": "ok",
     "timestamp": 1591978979552,
     "user": {
      "displayName": "Zhouyangguang Zhao",
      "photoUrl": "",
      "userId": "12804106343770884783"
     },
     "user_tz": 420
    },
    "id": "LR2jl-k5_iT-",
    "outputId": "7fa1744f-b417-4b8c-9799-99adb15de730"
   },
   "outputs": [],
   "source": [
    "Xlocs = np.hstack((data_noisy['ra'][:, np.newaxis],\n",
    "                   data_noisy['dec'][:, np.newaxis]))\n",
    "Ylocs = np.hstack((data_stacked['RA'][:, np.newaxis],\n",
    "                   data_stacked['DEC'][:, np.newaxis]))\n",
    "\n",
    "print(\"number of noisy points:  \", Xlocs.shape)\n",
    "print(\"number of stacked points:\", Ylocs.shape)\n",
    "\n",
    "# find all points within 0.9 arcsec.  This cutoff was selected\n",
    "# by plotting a histogram of the log(distances).\n",
    "dist, ind = crossmatch(Xlocs, Ylocs, max_distance=0.9 / 3600)\n",
    "\n",
    "noisy_mask = (~np.isinf(dist))\n",
    "stacked_mask = ind[noisy_mask]\n",
    "\n",
    "# select the data\n",
    "data_noisy = data_noisy[noisy_mask]\n",
    "X = X[noisy_mask]\n",
    "Xerr = Xerr[noisy_mask]\n",
    "\n",
    "data_stacked = data_stacked[stacked_mask]\n",
    "Y = Y[stacked_mask]\n",
    "Yerr = Yerr[stacked_mask]\n",
    "\n",
    "# double-check that our cross-match succeeded\n",
    "assert X.shape == Y.shape\n",
    "print(\"size after crossmatch:\", X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca98b30",
   "metadata": {
    "colab_type": "text",
    "id": "P6pciF_SB5_D"
   },
   "source": [
    "### 4. Define W matrix and calculate covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f98d451",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BWmBqYx2B7ka"
   },
   "outputs": [],
   "source": [
    "# first define mixing matrix W\n",
    "W = np.array([[0, 1, 0, 0, 0],    # g magnitude\n",
    "              [1, -1, 0, 0, 0],   # u-g color\n",
    "              [0, 1, -1, 0, 0],   # g-r color\n",
    "              [0, 0, 1, -1, 0],   # r-i color\n",
    "              [0, 0, 0, 1, -1]])  # i-z color\n",
    "\n",
    "X = np.dot(X, W.T)\n",
    "Y = np.dot(Y, W.T)\n",
    "\n",
    "# compute error covariance from mixing matrix\n",
    "Xcov = np.zeros(Xerr.shape + Xerr.shape[-1:])\n",
    "Xcov[:, range(Xerr.shape[1]), range(Xerr.shape[1])] = Xerr ** 2\n",
    "\n",
    "# each covariance C = WCW^T\n",
    "# best way to do this is with a tensor dot-product\n",
    "Xcov = np.tensordot(np.dot(Xcov, W.T), W, (-2, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9667e9b1",
   "metadata": {
    "colab_type": "text",
    "id": "J7RxmcwmACTg"
   },
   "source": [
    "### 5. Plot two raw data sets\n",
    "We choose ten percent of the points in each data sets to plot in comparison. As we can see from the result, before XD, the sigle epoch (right) has more noise than standard stars (left)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad37464",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 58190,
     "status": "error",
     "timestamp": 1591978979564,
     "user": {
      "displayName": "Zhouyangguang Zhao",
      "photoUrl": "",
      "userId": "12804106343770884783"
     },
     "user_tz": 420
    },
    "id": "2rEl2in8__CP",
    "outputId": "085958ec-80c8-466e-dd39-572e1b641e58"
   },
   "outputs": [],
   "source": [
    "# Fit and sample from the underlying distribution\n",
    "np.random.seed(42)\n",
    "X_sample = clf.sample(X.shape[0])\n",
    "\n",
    "# plot the results\n",
    "fig = plt.figure(figsize=(10, 3.75))\n",
    "fig.subplots_adjust(left=0.12, right=0.95,\n",
    "                    bottom=0.1, top=0.95,\n",
    "                    wspace=0.02, hspace=0.02)\n",
    "\n",
    "# only plot 1/10 of the stars for clarity\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.scatter(Y[::10, 2], Y[::10, 3], s=9, lw=0, c='k')\n",
    "ax1.set_ylabel('$r-i$')\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "ax2.scatter(X[::10, 2], X[::10, 3], s=9, lw=0, c='k')\n",
    "\n",
    "titles = [\"Standard Stars\", \"Single Epoch\"]\n",
    "ax = [ax1, ax2]\n",
    "\n",
    "for i in range(2):\n",
    "    ax[i].set_xlim(-0.6, 1.8)\n",
    "    ax[i].set_ylim(-0.6, 1.8)\n",
    "\n",
    "    ax[i].xaxis.set_major_locator(plt.MultipleLocator(0.5))\n",
    "    ax[i].yaxis.set_major_locator(plt.MultipleLocator(0.5))\n",
    "\n",
    "    ax[i].text(0.05, 0.95, titles[i],\n",
    "               ha='left', va='top', transform=ax[i].transAxes)\n",
    "\n",
    "    ax[i].set_xlabel('$g-r$')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54f6bbc",
   "metadata": {
    "colab_type": "text",
    "id": "pTFuA8DbDBYs"
   },
   "source": [
    "### 6. Calculate XD value\n",
    "We define compute_XD and save the result to pickle file. This cell is estimated to take a long running time (more than 20 minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f66f432",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1UsXr6UPAUKn"
   },
   "outputs": [],
   "source": [
    "def compute_XD(n_clusters=12, rseed=0, max_iter=100, verbose=True):\n",
    "    np.random.seed(rseed)\n",
    "    clf = XDGMM(n_clusters, max_iter=max_iter, tol=1E-5, verbose=verbose)\n",
    "    clf.fit(X, Xcov)\n",
    "    return clf\n",
    "\n",
    "clf = compute_XD(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2750cf",
   "metadata": {
    "colab_type": "text",
    "id": "lRGEEYfcDoyt"
   },
   "source": [
    "### 7. Plot results in comparison\n",
    "Here we plot the result of noisy data after XD in scattered points (lower left), with a cluster location estimation in ellipses, in comparison with the original two data sets.  \n",
    "After XD resampling, the resampled data distributes less scattered than the original noisy data. It also shows a better clustered pattern than the standard star distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a66246",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 873938,
     "status": "ok",
     "timestamp": 1591976850506,
     "user": {
      "displayName": "Brigitta Sipocz",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgSZ5lvx2m0gmkej0jid6to7H2aVpPwrDwknsPBVg=s64",
      "userId": "02384660603430700458"
     },
     "user_tz": 420
    },
    "id": "fGGFGJM-DXhq",
    "outputId": "171d543a-bf80-4f58-a95f-2de821e6d69e"
   },
   "outputs": [],
   "source": [
    "# Fit and sample from the underlying distribution\n",
    "np.random.seed(42)\n",
    "X_sample = clf.sample(X.shape[0])\n",
    "\n",
    "# plot the results\n",
    "fig = plt.figure(figsize=(5, 3.75))\n",
    "fig.subplots_adjust(left=0.12, right=0.95,\n",
    "                    bottom=0.1, top=0.95,\n",
    "                    wspace=0.02, hspace=0.02)\n",
    "\n",
    "# only plot 1/10 of the stars for clarity\n",
    "ax1 = fig.add_subplot(221)\n",
    "ax1.scatter(Y[::10, 2], Y[::10, 3], s=9, lw=0, c='k')\n",
    "\n",
    "ax2 = fig.add_subplot(222)\n",
    "ax2.scatter(X[::10, 2], X[::10, 3], s=9, lw=0, c='k')\n",
    "\n",
    "ax3 = fig.add_subplot(223)\n",
    "ax3.scatter(X_sample[::10, 2], X_sample[::10, 3], s=9, lw=0, c='k')\n",
    "\n",
    "ax4 = fig.add_subplot(224)\n",
    "for i in range(clf.n_components):\n",
    "    draw_ellipse(clf.mu[i, 2:4], clf.V[i, 2:4, 2:4], scales=[2],\n",
    "                 ec='k', fc='gray', alpha=0.2, ax=ax4)\n",
    "\n",
    "titles = [\"Standard Stars\", \"Single Epoch\",\n",
    "          \"Extreme Deconvolution\\n  resampling\",\n",
    "          \"Extreme Deconvolution\\n  cluster locations\"]\n",
    "ax = [ax1, ax2, ax3, ax4]\n",
    "\n",
    "for i in range(4):\n",
    "    ax[i].set_xlim(-0.6, 1.8)\n",
    "    ax[i].set_ylim(-0.6, 1.8)\n",
    "\n",
    "    ax[i].xaxis.set_major_locator(plt.MultipleLocator(0.5))\n",
    "    ax[i].yaxis.set_major_locator(plt.MultipleLocator(0.5))\n",
    "\n",
    "    ax[i].text(0.05, 0.95, titles[i],\n",
    "               ha='left', va='top', transform=ax[i].transAxes)\n",
    "\n",
    "    if i in (0, 1):\n",
    "        ax[i].xaxis.set_major_formatter(plt.NullFormatter())\n",
    "    else:\n",
    "        ax[i].set_xlabel('$g-r$')\n",
    "\n",
    "    if i in (1, 3):\n",
    "        ax[i].yaxis.set_major_formatter(plt.NullFormatter())\n",
    "    else:\n",
    "        ax[i].set_ylabel('$r-i$')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a95d5df",
   "metadata": {
    "colab_type": "text",
    "id": "JtSa12EyD46q"
   },
   "source": [
    "### 8. Plot width of Locus\n",
    "We plot the widths of standard stars, single epoch and XD resampled result in one graph.   \n",
    "On the x-axis shows the width of locus, also called w color, defined as \n",
    "$w = -0.227g + 0.792r - 0.567i + 0.05$.  \n",
    "$\\sigma_{G}$ of the Gaussian distribution fit is the smallest in XD resampled result. This shows the effectiveness of correcting and clustering noisy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c78d8b",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gKWinE3HD5wX"
   },
   "outputs": [],
   "source": [
    "# Second figure: the width of the locus\n",
    "fig = plt.figure(figsize=(5, 3.75))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "labels = ['single epoch', 'standard stars', 'XD resampled']\n",
    "linestyles = ['solid', 'dashed', 'dotted']\n",
    "for data, label, ls in zip((X, Y, X_sample), labels, linestyles):\n",
    "    g = data[:, 0]\n",
    "    gr = data[:, 2]\n",
    "    ri = data[:, 3]\n",
    "\n",
    "    r = g - gr\n",
    "    i = r - ri\n",
    "\n",
    "    mask = (gr > 0.3) & (gr < 1.0)\n",
    "    g = g[mask]\n",
    "    r = r[mask]\n",
    "    i = i[mask]\n",
    "\n",
    "    w = -0.227 * g + 0.792 * r - 0.567 * i + 0.05\n",
    "\n",
    "    sigma = sigmaG(w)\n",
    "\n",
    "    ax.hist(w, bins=np.linspace(-0.08, 0.08, 100), linestyle=ls,\n",
    "            histtype='step', label=label + '\\n\\t' + r'$\\sigma_G=%.3f$' % sigma,\n",
    "            density=True)\n",
    "\n",
    "ax.legend(loc=2)\n",
    "ax.text(0.95, 0.95, '$w = -0.227g + 0.792r$\\n$ - 0.567i + 0.05$',\n",
    "        transform=ax.transAxes, ha='right', va='top')\n",
    "\n",
    "ax.set_xlim(-0.07, 0.07)\n",
    "ax.set_ylim(0, 55)\n",
    "\n",
    "ax.set_xlabel('$w$')\n",
    "ax.set_ylabel('$N(w)$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45350760",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JTUrQsvWKc5E"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.11.1"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "source_map": [
   15,
   20,
   38,
   45,
   61,
   66,
   73,
   124,
   129,
   158,
   166,
   183,
   189,
   211,
   219,
   284,
   289,
   295,
   317,
   322,
   352,
   357,
   404,
   408,
   432,
   437,
   489,
   494,
   508,
   514,
   583,
   591,
   634
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}